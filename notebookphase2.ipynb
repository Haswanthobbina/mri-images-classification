{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 14832123,
          "sourceType": "datasetVersion",
          "datasetId": 1608934
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebooke61441bdf7",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haswanthobbina/mri-images-classification/blob/main/notebookphase2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "masoudnickparvar_brain_tumor_mri_dataset_path = kagglehub.dataset_download('masoudnickparvar/brain-tumor-mri-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ubksee1CiCig",
        "outputId": "eceecdaf-e9ec-49a4-8a5a-05cdd0a67348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/masoudnickparvar/brain-tumor-mri-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157M/157M [00:02<00:00, 81.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-14T08:57:24.888632Z",
          "iopub.execute_input": "2026-02-14T08:57:24.889191Z",
          "iopub.status.idle": "2026-02-14T08:57:27.949271Z",
          "shell.execute_reply.started": "2026-02-14T08:57:24.889164Z",
          "shell.execute_reply": "2026-02-14T08:57:27.948403Z"
        },
        "id": "8Vhf8oq_iCij"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =================================================================\n",
        "# ðŸš€ ULTIMATE MASTER SCRIPT: 5 DL Models + 3 Hybrid ML Models\n",
        "# =================================================================\n",
        "# FEATURES:\n",
        "#  1. Trains ResNet18, VGG16, MobileNetV2, EfficientNet, DenseNet.\n",
        "#  2. Extracts Deep Features (DenseNet) + Handcrafted Features (GLCM, Symmetry).\n",
        "#  3. Trains Random Forest, XGBoost, SVM on fused features.\n",
        "#  4. Generates a 'final_project_bundle.zip' with all models & metrics.\n",
        "\n",
        "# 1. INSTALL DEPENDENCIES\n",
        "!pip install -q kagglehub scikit-learn pandas xgboost scikit-image opencv-python\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import kagglehub\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. SETUP & DATA DOWNLOAD\n",
        "# ---------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Running on: {device}\")\n",
        "\n",
        "print(\"â¬‡ï¸ Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "TRAIN_DIR = os.path.join(path, \"Training\")\n",
        "TEST_DIR = os.path.join(path, \"Testing\")\n",
        "\n",
        "# Define Output Directory\n",
        "OUTPUT_DIR = \"/content/final_models_output\"\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# Data Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(TRAIN_DIR, transform=transform)\n",
        "test_data = datasets.ImageFolder(TEST_DIR, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. DEFINE DEEP LEARNING MODELS\n",
        "# ---------------------------------------------------------\n",
        "def get_model(model_name, pretrained=True):\n",
        "    weights = 'DEFAULT' if pretrained else None\n",
        "\n",
        "    if model_name == \"ResNet-18\":\n",
        "        model = models.resnet18(weights=weights)\n",
        "        model.fc = nn.Linear(model.fc.in_features, 4)\n",
        "\n",
        "    elif model_name == \"VGG-16\":\n",
        "        model = models.vgg16(weights=weights)\n",
        "        model.classifier[6] = nn.Linear(4096, 4)\n",
        "\n",
        "    elif model_name == \"MobileNetV2\":\n",
        "        model = models.mobilenet_v2(weights=weights)\n",
        "        model.classifier[1] = nn.Linear(model.last_channel, 4)\n",
        "\n",
        "    elif model_name == \"EfficientNet-B0\":\n",
        "        model = models.efficientnet_b0(weights=weights)\n",
        "        model.classifier[1] = nn.Linear(1280, 4)\n",
        "\n",
        "    elif model_name == \"DenseNet-121\":\n",
        "        model = models.densenet121(weights=weights)\n",
        "        model.classifier = nn.Linear(1024, 4)\n",
        "\n",
        "    return model.to(device)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. TRAIN & EVALUATE 5 DL MODELS\n",
        "# ---------------------------------------------------------\n",
        "dl_models = [\"ResNet-18\", \"VGG-16\", \"MobileNetV2\", \"EfficientNet-B0\", \"DenseNet-121\"]\n",
        "metrics_results = {}\n",
        "\n",
        "print(\"\\nðŸ”¥ STARTING DEEP LEARNING TRAINING...\")\n",
        "\n",
        "for name in dl_models:\n",
        "    print(f\"\\nâž¡ï¸ Processing {name}...\")\n",
        "    model = get_model(name)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train (3 Epochs)\n",
        "    model.train()\n",
        "    for epoch in range(5):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"   Epoch {epoch+1}: Loss {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    all_preds, all_labels, all_probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    # Calculate Metrics\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True, zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')\n",
        "    except:\n",
        "        auc = 0.0\n",
        "\n",
        "    safe_name = name.lower().replace(\"-\", \"\").replace(\"_\", \"\")\n",
        "    metrics_results[safe_name] = {\n",
        "        \"accuracy\": accuracy_score(all_labels, all_preds),\n",
        "        \"precision\": report['macro avg']['precision'],\n",
        "        \"recall\": report['macro avg']['recall'],\n",
        "        \"f1_score\": report['macro avg']['f1-score'],\n",
        "        \"auc_roc\": auc,\n",
        "        \"description\": f\"{name} Deep Learning Model\"\n",
        "    }\n",
        "\n",
        "    # SAVE MODEL\n",
        "    save_path = os.path.join(OUTPUT_DIR, f\"{safe_name}_brain_tumor.pth\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"   âœ… Saved {name} to {save_path}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. FEATURE ENGINEERING (Hybrid Extraction)\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nðŸ§¬ STARTING HYBRID FEATURE EXTRACTION...\")\n",
        "\n",
        "# A. Handcrafted Features Function\n",
        "def get_handcrafted_features(image_path):\n",
        "    try:\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None: return np.zeros(11) # Fallback\n",
        "        img = cv2.resize(img, (224, 224))\n",
        "\n",
        "        # Stats\n",
        "        mean_val = np.mean(img)\n",
        "        std_val = np.std(img)\n",
        "        var_val = np.var(img)\n",
        "        skew_val = skew(img.flatten())\n",
        "        kurt_val = kurtosis(img.flatten())\n",
        "\n",
        "        # Texture (GLCM)\n",
        "        glcm = graycomatrix(img, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "        contrast = graycoprops(glcm, 'contrast').mean()\n",
        "        dissimilarity = graycoprops(glcm, 'dissimilarity').mean()\n",
        "        homogeneity = graycoprops(glcm, 'homogeneity').mean()\n",
        "        energy = graycoprops(glcm, 'energy').mean()\n",
        "        correlation = graycoprops(glcm, 'correlation').mean()\n",
        "\n",
        "        # Symmetry\n",
        "        h, w = img.shape\n",
        "        left = img[:, :w//2]\n",
        "        right = img[:, w//2:]\n",
        "        right_flip = cv2.flip(right, 1)\n",
        "        right_flip = cv2.resize(right_flip, (left.shape[1], left.shape[0]))\n",
        "        asymmetry = np.mean(np.abs(left - right_flip))\n",
        "\n",
        "        return np.array([mean_val, std_val, var_val, skew_val, kurt_val,\n",
        "                         contrast, dissimilarity, homogeneity, energy, correlation, asymmetry])\n",
        "    except:\n",
        "        return np.zeros(11)\n",
        "\n",
        "# B. Load Deep Feature Extractor (DenseNet-121)\n",
        "feature_extractor = get_model(\"DenseNet-121\", pretrained=False)\n",
        "densenet_path = os.path.join(OUTPUT_DIR, \"densenet121_brain_tumor.pth\")\n",
        "feature_extractor.load_state_dict(torch.load(densenet_path))\n",
        "feature_extractor.classifier = nn.Identity()\n",
        "feature_extractor.eval()\n",
        "\n",
        "# C. Extraction Loop\n",
        "def extract_hybrid_data(dataset):\n",
        "    features_list, labels_list = [], []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        path, label = dataset.samples[i]\n",
        "\n",
        "        # 1. Deep Features\n",
        "        img_pil = Image.open(path).convert(\"RGB\")\n",
        "        tensor = transform(img_pil).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            deep_feat = feature_extractor(tensor).cpu().numpy().flatten()\n",
        "\n",
        "        # 2. Handcrafted Features\n",
        "        manual_feat = get_handcrafted_features(path)\n",
        "\n",
        "        # 3. Fuse\n",
        "        combined = np.hstack([deep_feat, manual_feat])\n",
        "\n",
        "        features_list.append(combined)\n",
        "        labels_list.append(label)\n",
        "\n",
        "        if i % 500 == 0: print(f\"   Processed {i}/{len(dataset)}...\", end='\\r')\n",
        "\n",
        "    return np.vstack(features_list), np.array(labels_list)\n",
        "\n",
        "print(\"   Extracting Training Features (This takes a moment)...\")\n",
        "X_train, y_train = extract_hybrid_data(train_data)\n",
        "print(f\"\\n   Training Features Shape: {X_train.shape}\")\n",
        "\n",
        "print(\"   Extracting Testing Features...\")\n",
        "X_test, y_test = extract_hybrid_data(test_data)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6. TRAIN ML MODELS (RF, XGB, SVM)\n",
        "# ---------------------------------------------------------\n",
        "ml_models_map = {\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    \"SVM\": SVC(probability=True)\n",
        "}\n",
        "\n",
        "print(\"\\nðŸ¤– TRAINING MACHINE LEARNING MODELS...\")\n",
        "for name, clf in ml_models_map.items():\n",
        "    print(f\"âž¡ï¸ Training {name}...\")\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    y_prob = clf.predict_proba(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='macro')\n",
        "    except:\n",
        "        auc = 0.0\n",
        "\n",
        "    metric_key = f\"ml_{name.lower()}\"\n",
        "    metrics_results[metric_key] = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": report['macro avg']['precision'],\n",
        "        \"recall\": report['macro avg']['recall'],\n",
        "        \"f1_score\": report['macro avg']['f1-score'],\n",
        "        \"auc_roc\": auc,\n",
        "        \"description\": f\"Hybrid Model: DenseNet + Handcrafted + {name}\"\n",
        "    }\n",
        "\n",
        "    joblib.dump(clf, os.path.join(OUTPUT_DIR, f\"{metric_key}.pkl\"))\n",
        "    print(f\"   âœ… Saved {name}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 7. SAVE METRICS & ZIP\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nðŸ“¦ ZIPPING FINAL RESULTS...\")\n",
        "with open(os.path.join(OUTPUT_DIR, \"model_metrics.json\"), \"w\") as f:\n",
        "    json.dump(metrics_results, f, indent=4)\n",
        "\n",
        "shutil.make_archive(\"/content/final_project_bundle\", 'zip', OUTPUT_DIR)\n",
        "\n",
        "from google.colab import files\n",
        "print(\"ðŸŽ‰ SUCCESS! Downloading 'final_project_bundle.zip'...\")\n",
        "files.download('/content/final_project_bundle.zip')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-14T08:57:27.950829Z",
          "iopub.execute_input": "2026-02-14T08:57:27.951284Z",
          "iopub.status.idle": "2026-02-14T09:32:05.433012Z",
          "shell.execute_reply.started": "2026-02-14T08:57:27.951258Z",
          "shell.execute_reply": "2026-02-14T09:32:05.432345Z"
        },
        "id": "GINdqsPZiCik",
        "outputId": "4207c096-95dd-4e98-d07b-7d2767e5020d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Running on: cuda\n",
            "â¬‡ï¸ Downloading dataset...\n",
            "Using Colab cache for faster access to the 'brain-tumor-mri-dataset' dataset.\n",
            "\n",
            "ðŸ”¥ STARTING DEEP LEARNING TRAINING...\n",
            "\n",
            "âž¡ï¸ Processing ResNet-18...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 189MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch 1: Loss 0.2309\n",
            "   Epoch 2: Loss 0.0416\n",
            "   Epoch 3: Loss 0.0222\n",
            "   Epoch 4: Loss 0.0214\n",
            "   Epoch 5: Loss 0.0079\n",
            "   âœ… Saved ResNet-18 to /content/final_models_output/resnet18_brain_tumor.pth\n",
            "\n",
            "âž¡ï¸ Processing VGG-16...\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528M/528M [00:06<00:00, 82.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch 1: Loss 0.3635\n",
            "   Epoch 2: Loss 0.1159\n",
            "   Epoch 3: Loss 0.0770\n",
            "   Epoch 4: Loss 0.0425\n",
            "   Epoch 5: Loss 0.0429\n",
            "   âœ… Saved VGG-16 to /content/final_models_output/vgg16_brain_tumor.pth\n",
            "\n",
            "âž¡ï¸ Processing MobileNetV2...\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.6M/13.6M [00:00<00:00, 137MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch 1: Loss 0.4833\n",
            "   Epoch 2: Loss 0.1240\n",
            "   Epoch 3: Loss 0.0472\n",
            "   Epoch 4: Loss 0.0223\n",
            "   Epoch 5: Loss 0.0170\n",
            "   âœ… Saved MobileNetV2 to /content/final_models_output/mobilenetv2_brain_tumor.pth\n",
            "\n",
            "âž¡ï¸ Processing EfficientNet-B0...\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.5M/20.5M [00:00<00:00, 159MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch 1: Loss 0.4085\n",
            "   Epoch 2: Loss 0.1017\n",
            "   Epoch 3: Loss 0.0528\n",
            "   Epoch 4: Loss 0.0348\n",
            "   Epoch 5: Loss 0.0263\n",
            "   âœ… Saved EfficientNet-B0 to /content/final_models_output/efficientnetb0_brain_tumor.pth\n",
            "\n",
            "âž¡ï¸ Processing DenseNet-121...\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.8M/30.8M [00:00<00:00, 194MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Epoch 1: Loss 0.2466\n",
            "   Epoch 2: Loss 0.0481\n",
            "   Epoch 3: Loss 0.0249\n",
            "   Epoch 4: Loss 0.0207\n",
            "   Epoch 5: Loss 0.0193\n",
            "   âœ… Saved DenseNet-121 to /content/final_models_output/densenet121_brain_tumor.pth\n",
            "\n",
            "ðŸ§¬ STARTING HYBRID FEATURE EXTRACTION...\n",
            "   Extracting Training Features (This takes a moment)...\n",
            "\n",
            "   Training Features Shape: (5600, 1035)\n",
            "   Extracting Testing Features...\n",
            "\n",
            "ðŸ¤– TRAINING MACHINE LEARNING MODELS...\n",
            "âž¡ï¸ Training RandomForest...\n",
            "   âœ… Saved RandomForest\n",
            "âž¡ï¸ Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [10:52:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ… Saved XGBoost\n",
            "âž¡ï¸ Training SVM...\n",
            "   âœ… Saved SVM\n",
            "\n",
            "ðŸ“¦ ZIPPING FINAL RESULTS...\n",
            "ðŸŽ‰ SUCCESS! Downloading 'final_project_bundle.zip'...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6f196ca2-f480-4403-b321-9f5fbd0ab5ae\", \"final_project_bundle.zip\", 608931834)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    }
  ]
}